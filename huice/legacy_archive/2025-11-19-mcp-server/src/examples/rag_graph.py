"""
å¢å¼ºçš„RAGç³»ç»Ÿ - ä½¿ç”¨LangGraphå®ç°å¤šç­–ç•¥å¬å›ä¼˜åŒ–

æ¶æ„è¯´æ˜:
1. Query Rewriter: å¯¹ç”¨æˆ·é—®é¢˜è¿›è¡Œæ”¹å†™ä¼˜åŒ–,ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“
2. Query Expander: æ‰©å±•æŸ¥è¯¢,æ·»åŠ åŒä¹‰è¯å’Œç›¸å…³æ¦‚å¿µ
3. Parallel Retrieval: å¹¶è¡Œä»çŸ¥è¯†åº“å¬å›æ•°æ®
4. Reranker: å¯¹å¬å›ç»“æœè¿›è¡Œé‡æ’åº
5. Synthesizer: æ±‡æ€»æ•´åˆç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

æå‡å¬å›å‡†ç¡®ç‡çš„ç­–ç•¥:
- å¤šæŸ¥è¯¢æ”¹å†™(Multi-Query Rewriting)
- æŸ¥è¯¢æ‰©å±•(Query Expansion)
- æ··åˆæ£€ç´¢(Hybrid Retrieval: å‘é‡+å…³é”®è¯)
- ç»“æœé‡æ’åº(Reranking)
- ä¸Šä¸‹æ–‡å‹ç¼©(Context Compression)
"""
"""
Copyright (c) 2025 Dean Wu. All rights reserved.
AuroraAI Project.
"""


import os
import operator
from typing import Annotated, TypedDict, List

from langgraph.graph import StateGraph, START, END, MessagesState
from langgraph.types import Send
from langchain_core.messages import SystemMessage, HumanMessage
from langchain.chat_models import init_chat_model
from pydantic import BaseModel, Field

# åˆå§‹åŒ–å¤§æ¨¡å‹
os.environ["DEEPSEEK_API_KEY"] = "sk-0828827353434c24b51dd30edcfa7f32"
model = init_chat_model("deepseek:deepseek-chat")


from langchain_milvus import Milvus, BM25BuiltInFunction

from langchain_ollama import OllamaEmbeddings
# type: ignore  MC80OmFIVnBZMlhsa0xUb3Y2bzZVMDl2YkE9PTpjZWJhZmJkZQ==

embeddings = OllamaEmbeddings(model="qwen3-embedding:0.6b", base_url="http://35.235.113.151:11434")
vector_store = Milvus(
    embedding_function=embeddings,
    connection_args={"uri": "http://121.40.159.60:19530"},
    builtin_function=BM25BuiltInFunction(),
    vector_field=["dense", "sparse"],
    collection_name="course_collection",
)

# ============================================================================
# æ•°æ®æ¨¡å‹å®šä¹‰ - ä½¿ç”¨Pydanticè¿›è¡Œç»“æ„åŒ–è¾“å‡º
# ============================================================================

class RewrittenQuery(BaseModel):
    """æ”¹å†™åçš„æŸ¥è¯¢"""
    original: str = Field(description="åŸå§‹æŸ¥è¯¢")
    rewritten: str = Field(description="æ”¹å†™åçš„æŸ¥è¯¢")
    strategy: str = Field(description="æ”¹å†™ç­–ç•¥,å¦‚: simplify, expand, rephrase, decompose")


class QueryRewriteOutput(BaseModel):
    """æŸ¥è¯¢æ”¹å†™çš„è¾“å‡º"""
    queries: List[RewrittenQuery] = Field(description="æ”¹å†™åçš„æŸ¥è¯¢åˆ—è¡¨,åº”åŒ…å«3-5ä¸ªä¸åŒç­–ç•¥çš„æŸ¥è¯¢å˜ä½“")


class RetrievalResult(TypedDict):
    """å•ä¸ªå¬å›ç»“æœ"""
    query: str  # ä½¿ç”¨çš„æŸ¥è¯¢
    content: str  # å¬å›çš„å†…å®¹
    score: float  # ç›¸å…³æ€§åˆ†æ•°
    metadata: dict  # å…ƒæ•°æ®


class RAGState(TypedDict):
    """RAGç³»ç»Ÿçš„å…¨å±€çŠ¶æ€"""
    original_question: str  # ç”¨æˆ·åŸå§‹é—®é¢˜
    rewritten_queries: List[dict]  # æ”¹å†™åçš„æŸ¥è¯¢åˆ—è¡¨
    retrieval_results: Annotated[List[RetrievalResult], operator.add]  # æ‰€æœ‰å¬å›ç»“æœ(å¹¶è¡Œç´¯åŠ )
    reranked_results: List[RetrievalResult]  # é‡æ’åºåçš„ç»“æœ
    final_answer: str  # æœ€ç»ˆç­”æ¡ˆ
    metadata: dict  # é¢å¤–çš„å…ƒæ•°æ®


class RetrievalWorkerState(TypedDict):
    """å•ä¸ªæ£€ç´¢Workerçš„çŠ¶æ€"""
    query: dict  # è¦å¤„ç†çš„æŸ¥è¯¢
    retrieval_results: Annotated[List[RetrievalResult], operator.add]  # å¬å›ç»“æœ


# ============================================================================
# èŠ‚ç‚¹å‡½æ•°å®šä¹‰
# ============================================================================

def query_rewriter(state: RAGState) -> dict:
    """
    é—®é¢˜æ”¹å†™èŠ‚ç‚¹ - ä½¿ç”¨LLMç”Ÿæˆå¤šä¸ªä¼˜åŒ–çš„æŸ¥è¯¢å˜ä½“

    ç­–ç•¥:
    1. ç®€åŒ–æŸ¥è¯¢ - å»é™¤å†—ä½™ä¿¡æ¯
    2. æ‰©å±•æŸ¥è¯¢ - æ·»åŠ ç›¸å…³ä¸Šä¸‹æ–‡
    3. é‡æ–°è¡¨è¿° - ä½¿ç”¨ä¸åŒçš„è¡¨è¾¾æ–¹å¼
    4. åˆ†è§£æŸ¥è¯¢ - å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜
    """
    original_question = state["original_question"]

    # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºçš„LLM
    structured_llm = model.with_structured_output(QueryRewriteOutput)

    # æ„å»ºæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŸ¥è¯¢ä¼˜åŒ–ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·çš„é—®é¢˜æ”¹å†™ä¸º3-5ä¸ªä¸åŒçš„æŸ¥è¯¢å˜ä½“,ä»¥æé«˜ä»å‘é‡æ•°æ®åº“æ£€ç´¢çš„å‡†ç¡®ç‡ã€‚

æ”¹å†™ç­–ç•¥:
1. original - ä¿ç•™åŸå§‹æŸ¥è¯¢
2. simplify - ç®€åŒ–æŸ¥è¯¢,å»é™¤å†—ä½™ä¿¡æ¯,æå–æ ¸å¿ƒå…³é”®è¯
3. expand - æ‰©å±•æŸ¥è¯¢,æ·»åŠ ç›¸å…³æ¦‚å¿µã€åŒä¹‰è¯å’ŒèƒŒæ™¯ä¿¡æ¯
4. rephrase - ç”¨ä¸åŒçš„è¡¨è¾¾æ–¹å¼é‡æ–°è¡¨è¿°é—®é¢˜
5. decompose - å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªå­é—®é¢˜

è¦æ±‚:
- æ¯ä¸ªæŸ¥è¯¢å˜ä½“åº”è¯¥ä½¿ç”¨ä¸åŒçš„ç­–ç•¥
- æ”¹å†™åçš„æŸ¥è¯¢åº”è¯¥æ›´å®¹æ˜“åŒ¹é…å‘é‡æ•°æ®åº“ä¸­çš„æ–‡æ¡£
- ä¿æŒæŸ¥è¯¢çš„è¯­ä¹‰ä¸å˜
- ç”Ÿæˆ3-5ä¸ªæŸ¥è¯¢å˜ä½“"""

    user_prompt = f"è¯·å°†ä»¥ä¸‹é—®é¢˜æ”¹å†™ä¸ºå¤šä¸ªæŸ¥è¯¢å˜ä½“:\n\n{original_question}"

    try:
        # è°ƒç”¨LLMç”Ÿæˆæ”¹å†™æŸ¥è¯¢
        response = structured_llm.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ])

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        rewritten_queries = [q.model_dump() for q in response.queries]

        print(f"ğŸ“ Query Rewriter: ç”Ÿæˆäº† {len(rewritten_queries)} ä¸ªæŸ¥è¯¢å˜ä½“")
        for i, q in enumerate(rewritten_queries, 1):
            print(f"  {i}. [{q['strategy']}] {q['rewritten']}")

    except Exception as e:
        print(f"âš ï¸ Query Rewriter å‡ºé”™: {e}, ä½¿ç”¨åŸå§‹æŸ¥è¯¢")
        # é™çº§å¤„ç†: åªä½¿ç”¨åŸå§‹æŸ¥è¯¢
        rewritten_queries = [{
            "original": original_question,
            "rewritten": original_question,
            "strategy": "original"
        }]
# pragma: no cover  MS80OmFIVnBZMlhsa0xUb3Y2bzZVMDl2YkE9PTpjZWJhZmJkZQ==

    return {"rewritten_queries": rewritten_queries}

def retrieval_worker(state: RetrievalWorkerState) -> dict:
    """
    æ£€ç´¢WorkerèŠ‚ç‚¹ - ä»çŸ¥è¯†åº“å¬å›æ•°æ®ï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰
    ä½¿ç”¨ similarity_search_with_score è·å–æ–‡æ¡£å’Œç›¸å…³æ€§åˆ†æ•°

    æ³¨æ„: æ­¤å‡½æ•°æ¥å—å•ä¸ªæŸ¥è¯¢ï¼Œä¼šè¢«å¹¶è¡Œè°ƒç”¨å¤šæ¬¡
    """
    query_dict = state["query"]
    query_text = query_dict.get("rewritten", query_dict.get("original", ""))
    strategy = query_dict.get("strategy", "unknown")

    all_results = []

    try:
        # ä½¿ç”¨ similarity_search_with_score è·å– (Document, score) å…ƒç»„åˆ—è¡¨
        docs_with_scores = vector_store.similarity_search_with_score(query_text, k=3)

        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        for doc, score in docs_with_scores:
            result = {
                "query": query_text,
                "content": doc.page_content,
                "score": float(score),  # ç¡®ä¿åˆ†æ•°æ˜¯floatç±»å‹
                "metadata": doc.metadata,
                "strategy": strategy
            }
            all_results.append(result)

        print(f"  âœ“ [{strategy}] æ£€ç´¢åˆ° {len(docs_with_scores)} ä¸ªæ–‡æ¡£")

    except Exception as e:
        print(f"  âœ— [{strategy}] æŸ¥è¯¢å¤±è´¥: {e}")
# noqa  Mi80OmFIVnBZMlhsa0xUb3Y2bzZVMDl2YkE9PTpjZWJhZmJkZQ==

    return {"retrieval_results": all_results}


# ============================================================================
# Reranker è¾…åŠ©å‡½æ•°
# ============================================================================

def _deduplicate_by_pk(results: List[dict]) -> List[dict]:
    """åŸºäº pk (ä¸»é”®) ç²¾ç¡®å»é‡"""
    seen_pks = set()
    deduped = []

    for result in results:
        pk = result.get("metadata", {}).get("pk")
        if pk is not None:
            if pk not in seen_pks:
                seen_pks.add(pk)
                deduped.append(result)
        else:
            # å¦‚æœæ²¡æœ‰ pkï¼Œä¿ç•™è¯¥ç»“æœ
            deduped.append(result)

    return deduped


def _evaluate_relevance_with_llm(result: dict, question: str, idx: int, total: int) -> float:
    """ä½¿ç”¨ LLM è¯„ä¼°å•ä¸ªæ–‡æ¡£çš„ç›¸å…³æ€§"""
    import re

    relevance_prompt = f"""è¯·è¯„ä¼°ä»¥ä¸‹æ–‡æ¡£å†…å®¹ä¸ç”¨æˆ·é—®é¢˜çš„ç›¸å…³æ€§,ç»™å‡º0-1ä¹‹é—´çš„åˆ†æ•°ã€‚
åªéœ€è¦è¾“å‡ºä¸€ä¸ªæ•°å­—(å¦‚: 0.85),ä¸è¦è§£é‡Šã€‚

ç”¨æˆ·é—®é¢˜: {question}

æ–‡æ¡£å†…å®¹: {result['content'][:600]}

ç›¸å…³æ€§åˆ†æ•° (0-1):"""

    try:
        response = model.invoke([HumanMessage(content=relevance_prompt)])
        score_text = response.content.strip()

        # æå–æ•°å­— (æ”¯æŒ 0.85, .85, 1, 0 ç­‰æ ¼å¼)
        match = re.search(r'0?\.\d+|[01](?:\.\d+)?', score_text)
        if match:
            llm_score = float(match.group())
            llm_score = max(0.0, min(1.0, llm_score))  # é™åˆ¶åœ¨ [0, 1]
        else:
            llm_score = result["score"]

        print(f"    [{idx}/{total}] LLMè¯„åˆ†: {llm_score:.3f} (åŸå§‹: {result['score']:.3f})")
        return llm_score

    except Exception as e:
        print(f"    [{idx}/{total}] LLMè¯„åˆ†å¤±è´¥: {e}, ä½¿ç”¨åŸå§‹åˆ†æ•°")
        return result["score"]


def _rerank_with_llm(results: List[dict], question: str, max_docs: int = 15) -> List[dict]:
    """ä½¿ç”¨ LLM é‡æ–°è¯„åˆ†å’Œæ’åº"""
    if len(results) > max_docs:
        print(f"  âŠ™ æ­¥éª¤2 - è·³è¿‡LLMé‡æ’åº (æ–‡æ¡£æ•° {len(results)} > {max_docs}), ä½¿ç”¨åŸå§‹åˆ†æ•°æ’åº")
        return sorted(results, key=lambda x: x["score"], reverse=True)

    print(f"  â³ æ­¥éª¤2 - LLMé‡æ’åº: æ­£åœ¨è¯„ä¼° {len(results)} ä¸ªæ–‡æ¡£...")

    try:
        reranked_results = []

        for idx, result in enumerate(results, 1):
            llm_score = _evaluate_relevance_with_llm(result, question, idx, len(results))

            # ç»“åˆåŸå§‹åˆ†æ•°å’ŒLLMåˆ†æ•° (LLMæƒé‡æ›´é«˜)
            final_score = 0.3 * result["score"] + 0.7 * llm_score

            reranked_result = result.copy()
            reranked_result["score"] = final_score
            reranked_result["original_score"] = result["score"]
            reranked_result["llm_score"] = llm_score
            reranked_results.append(reranked_result)

        # æŒ‰æ–°åˆ†æ•°æ’åº
        reranked_results.sort(key=lambda x: x["score"], reverse=True)
        print(f"  âœ“ æ­¥éª¤2 - LLMé‡æ’åºå®Œæˆ")
        return reranked_results

    except Exception as e:
        print(f"  âœ— æ­¥éª¤2 - LLMé‡æ’åºå¤±è´¥: {e}, ä½¿ç”¨åŸå§‹åˆ†æ•°æ’åº")
        return sorted(results, key=lambda x: x["score"], reverse=True)

# type: ignore  My80OmFIVnBZMlhsa0xUb3Y2bzZVMDl2YkE9PTpjZWJhZmJkZQ==

def _optimize_diversity(results: List[dict]) -> List[dict]:
    """å¤šæ ·æ€§ä¼˜åŒ– - ä¼˜å…ˆé€‰æ‹©ä¸åŒæ¥æºçš„æ–‡æ¡£"""
    diverse_results = []
    seen_sources = set()
    remaining_results = []

    for result in results:
        source = result.get("metadata", {}).get("source", "unknown")
        if source not in seen_sources:
            diverse_results.append(result)
            seen_sources.add(source)
        else:
            remaining_results.append(result)

    # æ·»åŠ å‰©ä½™ç»“æœ
    diverse_results.extend(remaining_results)

    return diverse_results, len(seen_sources)


def _print_reranker_summary(all_results: List[dict], unique_results: List[dict],
                           final_results: List[dict], top_k: int):
    """æ‰“å° Reranker å¤„ç†æ‘˜è¦"""
    print(f"\nâœ… Reranker å®Œæˆ:")
    print(f"   åŸå§‹ç»“æœ: {len(all_results)} ä¸ª")
    print(f"   å»é‡å: {len(unique_results)} ä¸ª")
    print(f"   æœ€ç»ˆè¿”å›: {len(final_results)} ä¸ª (Top-{top_k})")

    # æ‰“å° Top-3 ç»“æœé¢„è§ˆ
    if final_results:
        print(f"\nğŸ“‹ Top-3 ç»“æœé¢„è§ˆ:")
        for i, result in enumerate(final_results[:3], 1):
            source = result.get("metadata", {}).get("source", "unknown")
            score = result.get("score", 0)
            content_preview = result.get("content", "")[:80].replace("\n", " ")
            print(f"   {i}. [åˆ†æ•°: {score:.3f}] {content_preview}...")
            print(f"      æ¥æº: {source}")


# ============================================================================
# Reranker ä¸»å‡½æ•°
# ============================================================================

def reranker(state: RAGState) -> dict:
    """
    é‡æ’åºèŠ‚ç‚¹ - å¯¹å¬å›ç»“æœè¿›è¡Œæ™ºèƒ½å»é‡å’Œé‡æ’åº

    ä¼˜åŒ–ç­–ç•¥:
    1. åŸºäº pk (ä¸»é”®) å»é‡ - ç²¾ç¡®å»é‡
    2. ä½¿ç”¨LLMè¯„ä¼°ç›¸å…³æ€§ - é‡æ–°è¯„åˆ†
    3. å¤šæ ·æ€§ä¼˜åŒ– - ç¡®ä¿ç»“æœè¦†ç›–ä¸åŒæ¥æº
    4. Top-K é€‰æ‹© - è¿”å›æœ€ç›¸å…³çš„ç»“æœ
    """
    all_results = state["retrieval_results"]
    original_question = state["original_question"]

    if not all_results:
        print("âš ï¸ Reranker: æ²¡æœ‰å¬å›ç»“æœ")
        return {"reranked_results": []}

    print(f"\nğŸ¯ Reranker: å¼€å§‹å¤„ç† {len(all_results)} ä¸ªå¬å›ç»“æœ")

    # æ­¥éª¤1: PKå»é‡
    pk_deduped = _deduplicate_by_pk(all_results)
    print(f"  âœ“ æ­¥éª¤1 - PKå»é‡: {len(all_results)} -> {len(pk_deduped)} ä¸ªæ–‡æ¡£")

    # æ­¥éª¤2: LLMé‡æ’åº
    # reranked_results = _rerank_with_llm(pk_deduped, original_question)
    reranked_results = pk_deduped
    # æ­¥éª¤3: å¤šæ ·æ€§ä¼˜åŒ–
    diverse_results, num_sources = _optimize_diversity(reranked_results)
    print(f"  âœ“ æ­¥éª¤3 - å¤šæ ·æ€§ä¼˜åŒ–: è¦†ç›– {num_sources} ä¸ªä¸åŒæ¥æº")

    # æ­¥éª¤4: Top-K é€‰æ‹©
    top_k = 10
    final_results = diverse_results[:top_k]

    # æ‰“å°æ‘˜è¦
    _print_reranker_summary(all_results, pk_deduped, final_results, top_k)

    return {"reranked_results": final_results}


def synthesizer(state: RAGState) -> dict:
    """
    ç­”æ¡ˆåˆæˆèŠ‚ç‚¹ - ä½¿ç”¨LLMåŸºäºå¬å›çš„å†…å®¹ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

    ä¼˜åŒ–ç­–ç•¥:
    1. æ™ºèƒ½ä¸Šä¸‹æ–‡æ„å»º - åŒ…å«åˆ†æ•°å’Œæ¥æºä¿¡æ¯
    2. å¼•ç”¨æ ‡æ³¨ - æ ‡è®°ä¿¡æ¯æ¥æº
    3. è´¨é‡è¯„ä¼° - è¯„ä¼°ç­”æ¡ˆè´¨é‡
    4. é™çº§å¤„ç† - é”™è¯¯æ—¶è¿”å›ç»“æ„åŒ–æ‘˜è¦
    """
    question = state["original_question"]
    results = state["reranked_results"]

    if not results:
        return {"final_answer": "æŠ±æ­‰,æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ–‡æ¡£æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚è¯·å°è¯•æ¢ä¸€ç§æ–¹å¼æé—®ã€‚"}

    print(f"\nğŸ“ Synthesizer: å¼€å§‹ç”Ÿæˆç­”æ¡ˆ (åŸºäº {len(results)} ä¸ªæ–‡æ¡£)")

    # ========== æ„å»ºä¸Šä¸‹æ–‡ - åŒ…å«è¯¦ç»†çš„æ¥æºå’Œåˆ†æ•°ä¿¡æ¯ ==========
    context_parts = []
    top_n = min(5, len(results))  # ä½¿ç”¨ top-5 æˆ–æ›´å°‘çš„ç»“æœ

    for i, result in enumerate(results[:top_n], 1):
        source = result.get('metadata', {}).get('source', 'unknown')
        content = result.get('content', '')
        score = result.get('score', 0)

        # æ„å»ºå¸¦æœ‰å…ƒä¿¡æ¯çš„ä¸Šä¸‹æ–‡
        context_part = f"""[æ–‡æ¡£{i}]
æ¥æº: {source}
ç›¸å…³æ€§åˆ†æ•°: {score:.3f}
å†…å®¹:
{content}"""
        context_parts.append(context_part)

        print(f"  âœ“ æ–‡æ¡£{i}: {source[:50]}... (åˆ†æ•°: {score:.3f})")

    context = "\n\n" + "="*80 + "\n\n".join(context_parts)

    # ========== æ„å»ºæç¤ºè¯ ==========
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

è¦æ±‚:
1. **åŸºäºäº‹å®**: ç­”æ¡ˆå¿…é¡»ä¸¥æ ¼åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹,ä¸è¦ç¼–é€ ä¿¡æ¯
2. **æ ‡æ³¨æ¥æº**: åœ¨ç­”æ¡ˆä¸­æ ‡æ³¨ä¿¡æ¯æ¥æº,ä½¿ç”¨ [æ–‡æ¡£X] çš„æ ¼å¼
3. **ç»¼åˆä¿¡æ¯**: å¦‚æœå¤šä¸ªæ–‡æ¡£æä¾›äº†ç›¸å…³ä¿¡æ¯,è¯·ç»¼åˆæ‰€æœ‰ä¿¡æ¯ç»™å‡ºå®Œæ•´ç­”æ¡ˆ
4. **æ¸…æ™°å‡†ç¡®**: ç­”æ¡ˆè¦æ¸…æ™°ã€å‡†ç¡®ã€æœ‰æ¡ç†,ä½¿ç”¨åˆ†ç‚¹æˆ–åˆ†æ®µçš„æ–¹å¼ç»„ç»‡
5. **è¯šå®è¡¨è¾¾**: å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰è¶³å¤Ÿä¿¡æ¯å›ç­”æŸä¸ªæ–¹é¢,è¯·æ˜ç¡®è¯´æ˜

ç­”æ¡ˆç»“æ„å»ºè®®:
- å¼€å¤´: ç›´æ¥å›ç­”æ ¸å¿ƒé—®é¢˜
- ä¸­é—´: æä¾›è¯¦ç»†è§£é‡Šå’Œæ”¯æŒä¿¡æ¯
- ç»“å°¾: æ€»ç»“è¦ç‚¹æˆ–è¡¥å……è¯´æ˜"""

    user_prompt = f"""è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜:

{context}

ç”¨æˆ·é—®é¢˜: {question}

è¯·æä¾›è¯¦ç»†ã€å‡†ç¡®çš„ç­”æ¡ˆ:"""

    try:
        # è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
        print(f"  â³ æ­£åœ¨è°ƒç”¨ LLM ç”Ÿæˆç­”æ¡ˆ...")
        response = model.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ])

        final_answer = response.content.strip()

        # ========== æ·»åŠ å…ƒæ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯ ==========
        # ç»Ÿè®¡æ¥æº
        unique_sources = set()
        for result in results:
            source = result.get('metadata', {}).get('source', 'unknown')
            unique_sources.add(source)

        # è®¡ç®—å¹³å‡åˆ†æ•°
        avg_score = sum(r.get('score', 0) for r in results[:top_n]) / top_n if top_n > 0 else 0

        stats = f"""

{"="*80}
ğŸ“Š ç­”æ¡ˆå…ƒæ•°æ®:
- å‚è€ƒæ–‡æ¡£æ•°: {len(results)} ä¸ª (ä½¿ç”¨ top-{top_n} ç”Ÿæˆç­”æ¡ˆ)
- æ¥æºæ•°é‡: {len(unique_sources)} ä¸ªä¸åŒæ¥æº
- å¹³å‡ç›¸å…³æ€§åˆ†æ•°: {avg_score:.3f}

ğŸ“š å‚è€ƒæ¥æº:"""

        # åˆ—å‡ºæ‰€æœ‰æ¥æº
        for i, source in enumerate(sorted(unique_sources)[:5], 1):
            stats += f"\n  {i}. {source}"

        if len(unique_sources) > 5:
            stats += f"\n  ... è¿˜æœ‰ {len(unique_sources) - 5} ä¸ªæ¥æº"

        final_answer = final_answer + stats

        print(f"  âœ… LLM ç­”æ¡ˆç”ŸæˆæˆåŠŸ (é•¿åº¦: {len(final_answer)} å­—ç¬¦)")
        print(f"  âœ… å¹³å‡ç›¸å…³æ€§åˆ†æ•°: {avg_score:.3f}")

    except Exception as e:
        print(f"  âœ— Synthesizer å‡ºé”™: {e}")
        print(f"  âš ï¸ ä½¿ç”¨é™çº§ç­–ç•¥: è¿”å›ç»“æ„åŒ–æ‘˜è¦")

        # ========== é™çº§å¤„ç†: è¿”å›ç»“æ„åŒ–çš„æ–‡æ¡£æ‘˜è¦ ==========
        final_answer = f"""# åŸºäº {len(results)} ä¸ªç›¸å…³æ–‡æ¡£çš„ä¿¡æ¯æ‘˜è¦

**é—®é¢˜**: {question}

**æ³¨æ„**: LLM ç”Ÿæˆå¤±è´¥,ä»¥ä¸‹æ˜¯æ–‡æ¡£æ‘˜è¦ä¾›å‚è€ƒ:

"""

        for i, result in enumerate(results[:5], 1):
            source = result.get('metadata', {}).get('source', 'unknown')
            content = result.get('content', '')
            score = result.get('score', 0)

            # æˆªå–å†…å®¹é¢„è§ˆ
            content_preview = content[:300].replace('\n', ' ')
            if len(content) > 300:
                content_preview += "..."

            final_answer += f"""
## æ–‡æ¡£ {i} (ç›¸å…³æ€§: {score:.3f})
**æ¥æº**: {source}
**å†…å®¹**: {content_preview}

"""

        final_answer += f"""
---
ğŸ’¡ æç¤º: è¯·å°è¯•é‡æ–°æé—®æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚
é”™è¯¯ä¿¡æ¯: {str(e)}
"""

    return {"final_answer": final_answer}


# ============================================================================
# æ¡ä»¶è¾¹å‡½æ•°
# ============================================================================

def assign_retrieval_workers(state: RAGState) -> List[Send]:
    """
    åˆ†é…æ£€ç´¢ä»»åŠ¡ - ä¸ºæ¯ä¸ªæ”¹å†™çš„æŸ¥è¯¢åˆ›å»ºä¸€ä¸ªå¹¶è¡Œçš„æ£€ç´¢Worker

    ä½¿ç”¨LangGraphçš„Send APIå®ç°å¹¶è¡Œæ£€ç´¢
    æ¯ä¸ªæŸ¥è¯¢ä¼šè§¦å‘ä¸€ä¸ªç‹¬ç«‹çš„ retrieval_worker èŠ‚ç‚¹æ‰§è¡Œ
    """
    queries = state["rewritten_queries"]

    print(f"ğŸš€ åˆ†é… {len(queries)} ä¸ªå¹¶è¡Œæ£€ç´¢ä»»åŠ¡")

    # ä¸ºæ¯ä¸ªæŸ¥è¯¢åˆ›å»ºä¸€ä¸ªSendå¯¹è±¡,è§¦å‘å¹¶è¡Œæ‰§è¡Œ
    return [
        Send("retrieval_worker", {"query": query})
        for query in queries
    ]


# ============================================================================
# æ„å»ºGraph
# ============================================================================

def build_enhanced_rag_graph():
    """
    æ„å»ºå¢å¼ºçš„RAG Graph

    ä½¿ç”¨æ¡ä»¶è¾¹å®ç°å¹¶è¡Œæ£€ç´¢:
    - query_rewriter ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“
    - é€šè¿‡æ¡ä»¶è¾¹ assign_retrieval_workers ä¸ºæ¯ä¸ªæŸ¥è¯¢åˆ›å»ºå¹¶è¡Œä»»åŠ¡
    - å¤šä¸ª retrieval_worker å¹¶è¡Œæ‰§è¡Œ
    - æ‰€æœ‰ retrieval_worker å®Œæˆåï¼Œç»“æœè‡ªåŠ¨åˆå¹¶åˆ° retrieval_results
    - reranker å¯¹åˆå¹¶åçš„ç»“æœè¿›è¡Œå»é‡å’Œé‡æ’åº
    """

    # åˆ›å»ºStateGraph
    graph_builder = StateGraph(RAGState)

    # æ·»åŠ èŠ‚ç‚¹
    graph_builder.add_node("query_rewriter", query_rewriter)
    graph_builder.add_node("retrieval_worker", retrieval_worker)
    graph_builder.add_node("reranker", reranker)
    graph_builder.add_node("synthesizer", synthesizer)

    # æ·»åŠ è¾¹
    graph_builder.add_edge(START, "query_rewriter")

    # æ¡ä»¶è¾¹: ä» query_rewriter åˆ°å¤šä¸ªå¹¶è¡Œçš„ retrieval_worker
    # assign_retrieval_workers è¿”å› List[Send]ï¼Œæ¯ä¸ª Send è§¦å‘ä¸€ä¸ª retrieval_worker
    graph_builder.add_conditional_edges(
        "query_rewriter",
        assign_retrieval_workers,
        ["retrieval_worker"]
    )

    # æ‰€æœ‰ retrieval_worker å®Œæˆåè¿›å…¥ reranker
    # ç”±äº retrieval_results ä½¿ç”¨äº† operator.addï¼Œæ‰€æœ‰å¹¶è¡Œç»“æœä¼šè‡ªåŠ¨åˆå¹¶
    graph_builder.add_edge("retrieval_worker", "reranker")
    graph_builder.add_edge("reranker", "synthesizer")
    graph_builder.add_edge("synthesizer", END)

    # ç¼–è¯‘Graph
    graph = graph_builder.compile()

    return graph
graph = build_enhanced_rag_graph()

# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

if __name__ == "__main__":
    # æ„å»ºGraph
    rag_graph = build_enhanced_rag_graph()
    
    # æµ‹è¯•è¾“å…¥
    # test_question = "ä»€ä¹ˆæ˜¯LangGraph?å®ƒæœ‰å“ªäº›æ ¸å¿ƒç‰¹æ€§?"
    test_question = "ä»‹ç»ä¸€ä¸‹è¿™ä»½åŸ¹è®­å¤§çº²"
    initial_state = {
        "original_question": test_question,
        "rewritten_queries": [],
        "retrieval_results": [],
        "reranked_results": [],
        "final_answer": "",
        "metadata": {}
    }
    
    print("=" * 80)
    print("ğŸš€ å¯åŠ¨å¢å¼ºRAGç³»ç»Ÿ")
    print("=" * 80)
    print(f"ğŸ“¥ ç”¨æˆ·é—®é¢˜: {test_question}\n")
    
    # æ‰§è¡ŒGraph
    result = rag_graph.invoke(initial_state)
    
    print("\n" + "=" * 80)
    print("ğŸ“¤ æœ€ç»ˆç»“æœ")
    print("=" * 80)
    print(result["final_answer"])
    print("\n" + "=" * 80)
